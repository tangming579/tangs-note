## RabbitMQ

### 组成部分

- Broker：消息队列服务进程。此进程包括两个部分：Exchange和Queue。

  - Exchange：交换机。按一定的规则将消息路由转发到某个队列。

  - Queue：消息队列，存储消息的队列。

- Producer：消息生产者。生产方客户端将消息同交换机路由发送到队列中。

- Consumer：消息消费者。消费队列中存储的消息。

**Exchange的四种类型**

- **Direct**：绑定一个队列，生产者发送消息给Exchange会指定一个Routing Key，要求**该消息与一个特定的路由键完全匹配**。简单点说就是一对一的，点对点的发送。它是完全匹配、单播的模式。
- **Fanout** ：发送到交换机的消息都会被转发到与该交换机绑定的所有队列上。很像子网广播
- **Topic**：通过模式匹配分配消息的路由键属性
- **Headers** ：路由不是用routingKey进行路由匹配，而是在匹配请求头中所带的键值进行路由

### 如何保证消息不丢失

消息丢失主要分为 生产者丢失消息、消息列表丢失消息、消费者丢失消息。

##### 生产者丢失消息

RabbitMQ 提供 **transaction** 和 **confirm** 模式来确保生产者不丢消息。

- **transaction 机制**：发送消息前，开启事务(channel.txSelect)，然后发送消息，如果发送过程中出现什么异常，事务就会回滚（channel.txRollback()），如果发送成功则提交事务channel.txCommit()。事务卡顿会导致后面无法发送，官方说加入事务机制MQ会降速250倍。

- **confirm(发送方确认模式)模式用的居多**：一旦 channel 进入 confirm 模式，所有在该信道上发布的消息都将会被指派一个从1开始的唯一的ID，一旦消息被投递到所有匹配的队列之后，RabbitMQ 就会发送一个包含消息的唯一ID 的 ACK给生产者，这就使得生产者知道消息已经正确到达目的队列了，如果 RabbitMQ 没能处理该消息，则会发送一个 Nack (not acknowledged) 消息给你，你可以进行重试操作。

发送方确认模式是异步的，生产者应用程序在等待确认的同时，可以继续发送消息。当确认消息到达生产者应用程序，生产者应用程序的回调方法就会被触发来处理确认消息。

#####  消息列表 丢失消息

处理消息队列丢数据的情况，一般是开启持久化磁盘的配置。这个持久化配置可以和**confirm** 机制配合使用，你可以在消息持久化磁盘后，再给生产者发送一个 Ack 信号。这样，如果消息持久化磁盘之前，**RabbitMQ** 挂了后生产者收不到Ack信号，生产者会自动重发。

通过如下持久化设置，即使 RabbitMQ 挂了重启后也能恢复数据。

1. **durable** = true, 将 queue 的持久化设置为 true，则代表是一个持久的队列
2. 发送消息的时候将 **deliveryMode**=2（1：非持久化  2：持久化）

关于持久化其实是个权衡问题，持久化可能会导致系统QPS下降，所以一般仅对关键消息作持久化处理（根据业务重要程度），且应该保证关键消息的持久化不会导致系统性能瓶颈。

##### 消费者丢失消息

消费者丢失消息：消费者丢数据一般是因为**采用了自动确认消息模式**，改为手动确认消息即可！

消费者在收到消息之后，处理消息之前，会**自动回复**RabbitMQ已收到消息；如果这时处理消息失败，就会丢失该消息。

**解决方案**：处理消息成功后，手动回复确认消息。消费者跟消息队列的连接不中断，RabbitMQ 给了 Consumer 足够长的时间来处理消息，保证数据的最终一致性。

**注意点**：

1. 消费者接收到消息却没有确认消息，连接也未断开，则 RabbitMQ 认为该消费者繁忙，将不会给该消费者分发更多的消息。
2. 如果消费者接收到消息，在确认之前断开了连接或取消订阅，RabbitMQ 会认为消息没有被分发，然后重新分发给下一个订阅的消费者，这时可能存在消息重复消费的隐患，需要去重！

###  如何避免消息重复投递或重复消费

消息重复消费的场景大概可以分为 生产者端重复消费 和 消费者端重复消费，解决办法是是通过**幂等性**来保证重复消费的消息不对结果产生影响即可。

1. 消息生成时 RabbitMQ 内部 对每个生产的消息生成个 inner-msg-id，作为去重和幂等的依据（消息投递失败并重传），避免重复的消息进入队列。
2. 消息消费时 要求消息体中必须要有一个 bizId（对于同一业务全局唯一，如支付 ID、订单 ID、帖子 ID 等）作为去重的依据，避免同一条消息被重复消费。
3. 在 RocketMQ 中生产者发送消息前询问 RocketMQ 信息是否已发送过，或者通过Redis记录已查询记录。不过最好的还是直接在消费端去重消费。

### 如何保证消息顺序执行

##### 乱序情况

1. 一个 queue，有多个 consumer 去消费，每个 consumer 的执行时间是不固定的，无法保证先读到消息的 consumer 一定先完成操作。

2. 一个 queue 对应一个 consumer，但是 consumer 里面进行了**多线程**消费，这样也会造成消息消费顺序错误。

##### 解决乱序

1. 拆分多个 queue，每个 queue 一个 consumer，将三个有先后顺序的消息根据用户订单id 哈希后发送到同一个queue中，来保证消息的先后性。当然这样会造成吞吐量下降。

2. 一个 queue 对应一个 consumer，在 consumer 内部根据ID映射到不同内存队列，然后用内存队列做排队 分发给底层不同的 worker 来处理

### RabbitMQ 的集群

RabbitMQ 是基于主从（非分布式）做高可用性的。RabbitMQ 有三种模式：**单机模式、普通集群模式、镜像集群模式**。

##### 普通集群模式

在 N 台机器上启动 N 个 RabbitMQ 实例。创建的 queue 只会放在一个 RabbitMQ 实例上，但每个MQ实例都 同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。消费时如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。让集群中多个节点来服务某个 queue 的读写操作来提高吞吐量。

##### 镜像集群模式

RabbitMQ 的高可用模式，在镜像集群模式下，你创建的 queue无论元数据还是 queue 里的消息都会存在于多个实例上，每个 RabbitMQ 节点都有这个 queue 的全部数据的。写消息到 queue 的时候都会自动把消息同步到多个实例的 queue 上。RabbitMQ 有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候是可以要求数据同步到所有节点的，也可以要求同步到指定数量的节点，再次创建 queue 的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。

1. **优点**在于任何一个机器宕机了其它节点还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。
2. **缺点**在于消息需要同步到所有机器上，导致网络带宽压力和消耗很重。也是每个节点都放这个 queue 的完整数据。

## Kafka

### 组成部分

- Producer ：消息生产者，就是向 kafka broker 发消息的客户端。
- Consumer ：消息消费者，向 kafka broker 取消息的客户端。
- Topic ：可以理解为一个队列，一个 Topic 又分为一个或多个分区
- Broker ：一台 kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个 broker 可以容纳多个 topic。
- Partition：为了实现扩展性，一个非常大的 topic 可以分布到多个 broker上，每个 partition 是一个有序的队列。partition 中的每条消息都会被分配一个有序的id（offset）。将消息发给 consumer，kafka 只保证按一个 partition 中的消息的顺序，不保证一个 topic 的整体（多个 partition 间）的顺序。
- Segment：Partition在物理上由多个Segment数据文件组成，每个Segment数据文件都大小相等，按顺序读写

监控工具：

`EFAK（Eagle For Apache Kafka）`EFAK是开源可视化和管理软件。可以查询、可视化、监控kafka集群，是将 kafka 的集群数据转换为图形可视化的工具。

### 如何保证消息顺序执行

kafka每个partition中的消息在写入时都是有序的，消费时，每个partition只能被每一个group中的一个消费者消费，保证了消费时也是有序的。整个topic不保证有序。如果为了保证topic整个有序，那么将partition调整为1.

### Kafka 判断一个节点是否还活着

1. 节点必须可以维护和 ZooKeeper 的连接， Zookeeper 通过心跳机制检查每个节点的连接
2. 如果节点是个 follower,他必须能及时的同步 leader 的写操作，延时不能太久

### Kafka中的ISR、AR

- ISR：In-Sync Replicas 副本同步队列
- AR：Assigned Replicas 所有副本ISR是由leader维护，follower从leader同步数据有一些延迟（包括延迟时间replica.lag.time.max.ms和延迟条数replica.lag.max.messages两个维度, 当前最新的版本0.10.x中只支持replica.lag.time.max.ms这个维度），任意一个超过阈值都会把follower剔除出ISR, 存入OSR（Outof-Sync Replicas）列表，新加入的follower也会先存放在OSR中。AR=ISR+OSR。

### 与RabbitMQ区别

RabbitMQ：用于实时的，对可靠性要求较高的消息传递上。

kafka：优势主要体现在吞吐量上，主要用于处理活跃的流式数据，大数据量的数据处理上。