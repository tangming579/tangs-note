# 数据库

## MySQL

### 数据库优化

**优化顺序**

sql语句优化 -> 索引优化 -> 加缓存 -> 读写分离 -> 分区 -> 分布式数据库（垂直切分）-> 水平切分 

**设计表时要注意**

-  表字段避免null值出现，null值很难查询优化且占用额外的索引空间，推荐默认数字0代替null。
-  尽量使用INT而非BIGINT，如果非负则加上UNSIGNED（这样数值容量会扩大一倍），当然能使用TINYINT、SMALLINT、MEDIUM_INT更好。
-  使用枚举或整数代替字符串类型
-  尽量使用TIMESTAMP而非DATETIME
-  单表不要有太多字段，建议在20以内
-  用整型（unsigned int）来存IP（1.方便分段查询；2.节省空间）

**索引**

-  索引并不是越多越好，要根据查询有针对性的创建，考虑在WHERE和ORDER BY命令上涉及的列建立索引，可根据EXPLAIN来查看是否用了索引还是全表扫描
-  应尽量避免在WHERE子句中对字段进行NULL值判断，否则将导致引擎放弃使用索引而进行全表扫描
-  值分布很稀少的字段不适合建索引，例如"性别"这种只有两三个值的字段
-  字符字段只建前缀索引
-  字符字段最好不要做主键
-  不用外键，由程序保证约束
-  尽量不用UNIQUE，由程序保证约束
-  使用多列索引时主意顺序和查询条件保持一致，同时删除不必要的单列索引

**简言之就是使用合适的数据类型，选择合适的索引**

1.选择合适的数据类型

- （1）使用可存下数据的最小的数据类型，整型 < date,time < char,varchar < blob
- （2）使用简单的数据类型，整型比字符处理开销更小，因为字符串的比较更复杂。如，int类型存储时间类型，bigint类型转ip函数
- （3）使用合理的字段属性长度，固定长度的表会更快。使用enum、char而不是varchar
- （4）尽可能使用not null定义字段
- （5）尽量少用text，非用不可最好分表

 2.选择合适的索引列

- （1）查询频繁的列，在where，group by，order by，on从句中出现的列
- （2）where条件中<，<=，=，>，>=，between，in，以及like 字符串+通配符（%）出现的列
- （3）长度小的列，索引字段越小越好，因为数据库的存储单位是页，一页中能存下的数据越多越好
- （4）离散度大（不同的值多）的列，放在联合索引前面。查看离散度，通过统计不同的列值来实现，count越大，离散程度越高：

**sql的编写需要注意优化**

-  使用limit对查询结果的记录进行限定
-  避免select *，将需要查找的字段列出来
-  使用连接（join）来代替子查询
-  拆分大的delete或insert语句
-  可通过开启慢查询日志来找出较慢的SQL
-  不做列运算：SELECT id WHERE age + 1 = 10，任何对列的操作都将导致表扫描，它包括数据库教程函数、计算表达式等等，查询时要尽可能将操作移至等号右边
-  sql语句尽可能简单：一条sql只能在一个cpu运算；大语句拆小语句，减少锁时间；一条大sql可以堵死整个库
-  OR改写成IN：OR的效率是n级别，IN的效率是log(n)级别，in的个数建议控制在200以内
-  不用函数和触发器，在应用程序实现
-  避免%xxx式查询
-  少用JOIN
-  使用同类型进行比较，比如用'123'和'123'比，123和123比
-  尽量避免在WHERE子句中使用!=或<>操作符，否则将引擎放弃使用索引而进行全表扫描
-  对于连续数值，使用BETWEEN不用IN：SELECT id FROM t WHERE num BETWEEN 1 AND 5
-  列表数据不要拿全表，要使用LIMIT来分页，每页数量也不要太大

**MyISAM和InnoDB的区别**

1. InnoDB支持事务，MyISAM不支持，对于InnoDB每一条SQL语言都默认封装成事务，自动提交，这样会影响速度，所以最好把多条SQL语言放在begin和commit之间，组成一个事务； 
2. InnoDB支持外键，而MyISAM不支持。对一个包含外键的InnoDB表转为MYISAM会失败； 
3. InnoDB不保存表的具体行数，执行select count(*) from table时需要全表扫描。而MyISAM用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快； 
4. Innodb不支持全文索引，而MyISAM支持全文索引，查询效率上MyISAM要高； 
5. 锁机制不同: InnoDB 为行级锁，myisam 为表级锁。 

**索引查找、索引扫描**

全表扫描：读取表中所有的行
索引扫描：类似全表扫描
索引查找：定位到索引指向的局部位置

- 隐式转换容易从索引查找变成索引扫描

- where子句中的谓词不是联合索引的第一列对于联合索引最左边一列存有统计信息，其他列sqlserver不存统计信息

- where 子句里串联会导致索引失效 where A+B = ... (索引为A，B联合索引)

- =,>,<,>=,<=,between,以及部分like(like'%XXX') 
- 两个相关联的表的格式不一致

**什么是全表扫描**

全表扫描 (又称顺序扫描) 就是在数据库中进行逐行扫描，顺序读取表中的每一行记录，然后检查各个列是否符合查询条件。这种扫描是已知最慢的，因为需要进行大量的磁盘 I/O，而且从磁盘到内存的传输开销也很大。

**为什么数据库的性能瓶颈一般出现在IO上面**

IO永远是数据库最容易瓶颈的地方，大部分数据库操作中超过90%的时间都是 IO 操作所占用的，减少 IO 次数是 SQL 优化中需要第一优先考虑。

innodb_buffer池相关的，以及跟读数据块最相关的核心函数buf_page_get_gen函数以及其调用的相关子函数

buf_page_get_gen函数的作用是从Buffer bool里面读数据页

**回表**

由于辅助索引只存储主键的值,如果使用辅助索引搜索数据就必须先从辅助索引取到主键的值,再使用主键的值去主键索引上查询,直到找到叶子节点上的数据返回

如果查询的列本身就存在于索引中，那么即使使用辅助索引，一样也是不需要回表的。

**联合索引**

联合索引是指对表上的多个列进行索引，联合索引也是一棵B+树，不同的是联合索引的键值数量不是1，而是大于等于2，联合索引的查询要尽量符合最左匹配原则

优化：在联合索引中将选择性最高的列放在索引最前面。

**覆盖索引**

SQL只需要通过索引就可以返回查询所需要的数据，而不必通过二级索引查到主键之后再去查询数据

判断标准：使用explain，可以通过输出的extra列来判断，对于一个索引覆盖查询，显示为**using index**

### 日志

- redo log：重做日志，记录数据改变之后的值（InnoDB事务日志）

- undo log：撤销日志，记录事务发生前数据的值（InnoDB事务日志）

- binlog：归档日志，记录日志sql语句，用于数据库基于时间点的还原，主从复制（Server层面日志）
- errorlog：错误日志
- slow query log：慢查询日志

#### redo

- 一是内存中重做日志缓冲 (redo log buffer)，是易失的，在内存中
- 二是重做日志文件 (redo log file)，是持久的，保存在磁盘中

事务开始之后就产生redo log，整体流程

- 第一步：先将原始数据从磁盘中读入内存中来，修改数据的内存拷贝
- 第二步：生成一条重做日志并写入redo log buffer，记录的是数据被修改后的值
- 第三步：当事务commit时，将redo log buffer中的内容刷新到 redo log file，对 redo log file采用追加写的方式
- 第四步：定期将内存中修改的数据刷新到磁盘中

> 例如某一事务的事务序号为T1，其对数据X进行修改，设X的原值是5，修改后的值为15，那么
>
> Undo日志为<T1, X, 5>
>
> Redo日志为<T1, X, 15>。

#### undo

- 产生：事务开始之前，将当前是的版本生成undo log，undo 也会产生 redo 来保证undo log的可靠性
- 释放：当事务提交之后，undo log并不能立马被删除，而是放入待清理的链表，由purge线程判断定是否可以清理undo log的日志空间

#### binlog

逻辑格式的日志，可以简单认为就是执行过的事务中的sql语句。但又不完全是sql语句这么简单，而是包括了执行的sql语句（增删改）反向的信息

- 产生：事务提交的时候，一次性将事务中的sql语句（一个事物可能对应多个sql语句）按照一定的格式记录到binlog中。
- 释放：在生成时间超过expire_logs_days配置的天数之后，会被自动删除

binlog与redo log区别：

- redo log是保证事务的持久性的，是事务层面的，binlog作为还原的功能，是数据库层面的
- redo log是物理日志，是数据页面的修改之后的物理记录，binlog是逻辑日志，记录的是sql语句
- 两者日志产生的时间，可以释放的时间，在可释放的情况下清理机制，都是完全不同的
- 恢复数据时候的效率，基于物理日志的redo log恢复数据的效率要高于语句逻辑日志的binlog

### InnoDB逻辑存储结构

所有的数据都被存放在一个空间中，被称为表空间，表空间又分为段、区、页

- 段：数据段（B+树的叶子节点）、索引段（B+树的非叶子节点）、回滚段
- 区：由连续的页组成的空间，默认1M，一个区默认有64个页
- 页：InnoDB磁盘管理的最小单位，默认16KB，可通过innodb_page_size字段修改为4K、8K、16K
- 行：具体数据

### 事务

**事务的ACID**

1. 原子性：整个事务中的所有操作，要么全部完成，要么全部不完成 

   （由redo/undo log日志保证，它记录了需要回滚的日志信息，事务回滚时撤销已经执行成功的sql）

2. 一致性：事务前后数据的完整性必须保持一致。另一种说法：保证事务只能把数据库从一个有效（正确）的状态“转移”到另一个有效（正确）的状态

   （原子性、隔离性、持久性都是为了最终实现一致性）

3. 隔离性：同一时间仅有一个请求用于同一数据（MVCC来保证）

4. 持久性：在事务完成以后，该事务对数据库所作的更改便持久的保存在数据库之中，并不会被回滚

   （由内存+redo log来保证，mysql修改数据同时在内存和redo log记录这次操作，事务提交的时候通过redo log刷盘，宕机的时候可以从redo log恢复）

**事务的隔离级别**

1. Read Uncommitted（未提交读） ：事务中的修改，即使没有提交，其他事务也可以看得到，会导致“脏读”、“幻读”和“不可重复读取;
2. READ COMMITTED （提交读）：大多数主流数据库的默认事务等级，保证了一个事务不会读到另一个并行事务已修改但未提交的数据，避免了“脏读”，但不能避免“幻读”和“不可重复读取”。该级别适用于大多数系统。
3. REPEATABLE READ（重复读） ：保证了一个事务不会修改已经由另一个事务读取但未提交（回滚）的数据。避免了“脏读取”和“不可重复读取”的情况，但不能避免“幻读”，但是带来了更多的性能损失。
4. Serializable （串行化）：最严格的级别，事务串行执行，资源消耗最大；

脏读：读取了另一个事务未提交的数据

不可重复读：读取一次，在第二次**读**之前更新了这个数据导致两次数据不同。

幻读：读取一次，在读第二次之前insert或者是delete，导致读取的**记录数**不同

​		   综上，不可重复读针对的是同一数据两次结果不同，幻读针对的是一片数据数量不同。

**锁的类型**

- 基于锁的属性分类：共享锁（S锁）、排他锁（X锁）。

- 基于锁的粒度分类：表锁、行锁、记录锁、间隙锁、临键锁。

- 基于锁的状态分类：意向共享锁、意向排它锁。

只有增、删、改才会加上排它锁，而只是查询并不会加锁，只能通过在select语句后显式加lock in share mode或者for update来加共享锁或者排它锁。

### MVCC

MVCC 多版本控制实现读取数据不用加锁， 可以让读取数据同时修改。修改数据时同时可读取。

最早的数据库系统，只有读读之间可以并发，读写，写读，写写都要阻塞。引入多版本之后，只有写写之间相互阻塞，其他三种操作都可以并行，这样大幅度提高了InnoDB的并发度。

MVCC 的实现依赖：隐藏字段、Read View、Undo log

- 隐藏字段

   InnoDB存储引擎在每行数据的后面添加了三个隐藏字段：

      1. DB_TRX_ID：表示最近一次对本记录行作修改（insert | update）的事务ID。
      2. DB_ROLL_PTR：回滚指针，指向当前记录行的undo log信息
      3. DB_ROW_ID：随着新行插入而单调递增的行ID（跟MVCC关系不大）

- Read View 

  > 在innodb 中每个SQL语句执行前都会创建一个快照（read_view）。快照主要保存了当前数据库系统中正处于活跃（没有commit）的事务的ID号（即trx_ids），其实简单的说这个快照中保存的是系统中当前不应该被本事务看到的其他事务id列表。

  1. low_limit_id：目前出现过的最大的事务ID+1，即下一个将被分配的事务ID

  2. up_limit_id：活跃事务列表trx_ids中最小的事务ID，如果trx_ids为空，则up_limit_id 为 low_limit_id

  3. trx_ids：Read View创建时其他未提交的活跃事务ID列表

     注意：Read View中trx_ids的活跃事务，不包括当前事务自己和已提交的事务（正在内存中）

  4.  creator_trx_id：当前创建事务的ID，是一个递增的编号 

- Undo log

  Undo log 主要用于记录数据被修改之前的日志，在表信息修改之前先会把数据拷贝到undo log 里，当事务进行回滚时可以通过undo log 里的日志进行数据还原。

```
  1. 如果 trx_id < up_limit_id, 那么表明“最新修改该行的事务”在“当前事务”创建快照之前就提交了，所以该记录行的值对当前事务是可见的。跳到步骤5。
  2. 如果 trx_id >= low_limit_id, 那么表明“最新修改该行的事务”在“当前事务”创建快照之后才修改该行，所以该记录行的值对当前事务不可见。跳到步骤4。
  3. 如果 up_limit_id <= trx_id < low_limit_id, 表明“最新修改该行的事务”在“当前事务”创建快照的时候可能处于“活动状态”或者“已提交状态”；所以就要对活跃事务列表trx_ids进行查找（源码中是用的二分查找，因为是有序的）：
     - 如果在活跃事务列表trx_ids中能找到 id 为 trx_id 的事务，表明①在“当前事务”创建快照前，“该记录行的值”被“id为trx_id的事务”修改了，但没有提交；或者②在“当前事务”创建快照后，“该记录行的值”被“id为trx_id的事务”修改了（不管有无提交）；这些情况下，这个记录行的值对当前事务都是不可见的，跳到步骤4；
     - 在活跃事务列表中找不到，则表明“id为trx_id的事务”在修改“该记录行的值”后，在“当前事务”创建快照前就已经提交了，所以记录行对当前事务可见，跳到步骤5。
  4. 在该记录行的 DB_ROLL_PTR 指针所指向的undo log回滚段中，取出最新的的旧事务号DB_TRX_ID, 将它赋给trx_id，然后跳到步骤1重新开始判断。
  5. 将该可见行的值返回。
```

select的时候InnoDB使用mvcc

select for update/select lock in share mode、/update/insert/delete的时候两阶段锁

### 主从复制

1. master开启bin-log功能，日志文件用于记录数据库的读写增删
2. 需要开启3个线程，master IO线程，slave开启 IO线程 SQL线程
3. Slave 通过IO线程连接master，并且请求某个bin-log，position之后的内容。
4. MASTER服务器收到slave IO线程发来的日志请求信息，io线程去将bin-log内容，position返回给slave IO线程。
5. slave服务器收到bin-log日志内容，将bin-log日志内容写入relay-log中继日志，创建一个master.info的文件，该文件记录了master ip 用户名 密码 master bin-log名称，bin-log position。
6. slave端开启SQL线程，实时监控relay-log日志内容是否有更新，解析文件中的SQL语句，在slave数据库中去执行。

## Redis

### 数据类型

| 结构类型         | 结构存储的值                                                 | 结构的读写能力                                               |
| ---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| String           | 可以是字符串、整数或者浮点数                                 | 对整个字符串或者字符串的其中一部分执行操作；对整数和浮点数执行自增（increment）或者自减（decrement）操作 |
| List             | 一个链表，链表上的每个节点都包含了一个字符串                 | 从脸部的两端推入或者弹出元素；根据偏移量对链表进行修剪（trim）；读取单个或者多个元素；根据值查找或者移除元素 |
| Set              | 包含字符串的无序收集器（unordered collection），并且被包含的每个字符串都是独一无二、各不相同的 | 添加、获取、移除单个元素；检查一个元素是否存在于集合中；计算交集、并集、差集；从集合里面随机获取元素 |
| Hash             | 包含键值对的无序散列表                                       | 添加、获取、移除单个键值对；获取所有键值对                   |
| ZSet（有序集合） | 字符串成员（member）与浮点数分值（score）之间的有序映射，元素的排列顺序由分值的大小决定 | 添加、获取、删除单个元素；根据分值范围（range）或者成员来获取元素 |

### 并发

#### 缓存穿透

大量请求了缓存和数据库中都没有的数据，每次都查询数据库，导致数据库压力过大

**解决方案**

1. 接口层增加校验，如用户鉴权校验，id做基础校验，id<=0的直接拦截
2. 加判断逻辑：将key-value对写为key-null，缓存有效时间可以设置短点，如30s（防止恶意攻击每次key不一样）
3. 设置过滤规则, 如布隆过滤器：布隆过滤器：将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，参考：https://www.cnblogs.com/wy123/p/11571215.html

#### 缓存击穿

一个key非常热点，在不停的扛着大并发，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞

**解决方案**

1. 热点数据永不过期
2. 使用互斥锁（mutex），思路就是只让一个线程构建缓存，其他线程等待构建缓存的线程执行完，重新从缓存获取数据

#### 缓存雪崩

某些原因，导致缓存**集体**过期（缓存击穿是单个key），如果此时出现高并发的请求出现，这些请求会全部指向数据库层，缓存层失去了对数据库层的保护，导致数据库承担绝大压力的情况。

**解决方案**

1. 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。
2. 如果缓存数据库是分布式部署，将热点数据均匀分布在不同搞得缓存数据库中。
3. 设置热点数据永远不过期。
4. 服务降级限流

### 过期策略

过期策略通常有一下三种：

- 定时删除：每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。

- 惰性删除：只有当访问一个key时，才会判断该key是否已过期，过期则清除。该策略可以最大化地节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。

- 定期删除：每隔一段时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的折中方案。

  定期删除可以通过：

  - 第一、配置redis.conf 的hz选项，默认为10 （即1秒执行10次，100ms一次，随机抽取一些设置了过期时间的 key，检查其是否过期，如果过期就删除。） 
  - 第二、配置redis.conf的maxmemory最大值，当已用内存超过maxmemory限定时，就会触发主动清理策略（内存淘汰机制）

Redis中同时使用了惰性过期和定期过期两种过期策略。

### 内存满了怎么办

1. 增加内存
2. 内存淘汰策略
   - LRU，即：最近最少使用淘汰算法（Least Recently Used）。LRU是淘汰最长时间没有被使用的数据。其核心思想就是“如果数据最近被访问过，那么将来被访问的几率也更高”。基本思路：如果最近使用得比较多的数据就把他放到列表头部，依次更新，从列表尾部的依次淘汰，就是删除对应的key。
   - LFU，即：最不经常使用淘汰算法（Least Frequently Used）。LFU是淘汰一段时间内，使用次数最少的数据。它是基于“如果一个数据在最近一段时间内使用次数很少，那么在将来一段时间内被使用的可能性也很小”的思路。

### 分布式锁



### 持久化

- Redis DataBase(简称RDB)
  - 执行机制：快照，直接将databases中的key-value的二进制形式存储在了rdb文件中
  - 优点：性能较高（因为是快照，且执行频率比aof低，而且rdb文件中直接存储的是key-values的二进制形式，对于恢复数据也快）
  - 使用单独子进程来进行持久化，主进程不会进行任何IO操作，保证了redis的高性能
  - 缺点：在save配置条件之间若发生宕机，此间的数据会丢失
  - RDB是间隔一段时间进行持久化，如果持久化之间redis发生故障，会发生数据丢失。所以这种方式更适合数据要求不严谨的时候
- Append-only file (简称AOF)
  - 执行机制：将对数据的每一条修改命令追加到aof文件
  - 优点：数据不容易丢失
  - 可以保持更高的数据完整性，如果设置追加file的时间是1s，如果redis发生故障，最多会丢失1s的数据；且如果日志写入不完整支持redis-check-aof来进行日志修复；AOF文件没被rewrite之前（文件过大时会对命令进行合并重写），可以删除其中的某些命令（比如误操作的flushall
  - 缺点：性能较低（每一条修改操作都要追加到aof文件，执行频率较RDB要高，而且aof文件中存储的是命令，对于恢复数据来讲需要逐行执行命令，所以恢复慢）
  - AOF文件比RDB文件大，且恢复速度慢。

### 分布式集群部署

redis的多机数据库实现，主要分为以下三种：

1. Redis哨兵（Sentinel）
2. Redis复制（主从）
3. Redis集群

#### Redis复制（主从）

当开启主从模式的时候，他的具体工作机制如下：

1. 当slave启动后会向master发送`SYNC`命令，master节后到从数据库的命令后通过`bgsave`保存快照（**「RDB持久化」**），并且期间的执行的些命令会被缓存起来。
2. 然后master会将保存的快照发送给slave，并且继续缓存期间的写命令。
3. slave收到主数据库发送过来的快照就会加载到自己的数据库中。
4. 最后master讲缓存的命令同步给slave，slave收到命令后执行一遍，这样master与slave数据就保持一致了。

优点：

- 解决了单机版并发量大，导致请求延迟或者redis宕机服务停止的问题。
- 实现读写分离
- 一定程度上提高了系统的可用性和性能，是实现哨兵和集群的基础

缺点：

- 数据的一致性问题
- 主从模式不具备自动容错和恢复的功能

#### 哨兵（Sentinel）模式

为了解决Redis的主从复制的不支持高可用性能，Redis实现了Sentinel哨兵机制解决方案。主从切换技术的方法是：当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造成一段时间内服务不可用。这不是一种推荐的方式，更多时候，我们优先考虑哨兵模式。

哨兵模式是一种特殊的模式，首先Redis提供了哨兵的命令，哨兵是一个独立的进程，作为进程，它会独立运行。其原理是哨兵通过发送命令，等待Redis服务器响应，从而监控运行的多个Redis实例。

这里的哨兵有两个作用

- 通过发送命令，让Redis服务器返回监控其运行状态，包括主服务器和从服务器。
- 当哨兵监测到master宕机，会自动将slave切换成master，然后通过**发布订阅模式**通知其他的从服务器，修改配置文件，让它们切换主机。

然而一个哨兵进程对Redis服务器进行监控，可能会出现问题，为此，我们可以使用多个哨兵进行监控。各个哨兵之间还会进行监控，这样就形成了多哨兵模式。

#### 集群（Cluster）

哨兵解决主从不能自动故障恢复的问题，但是同时也存在难以扩容以及单机存储、读写能力受限的问题，并且集群之前都是一台redis都是全量的数据，这样所有的redis都冗余一份，就会大大消耗内存空间。

集群是Redis提供的分布式数据库方案，集群通过分片来进行数据共享，并提供复制和故障转移功能。一个Redis集群通常由多个节点组成；最初，每个节点都是独立的，需要将独立的节点连接起来才能形成可工作的集群。

在Redis集群中采用的使虚拟槽分区算法，会把redis集群分成16384 个槽（0 -16383）。

Cluster Nodes命令和Cluster Meet命令，添加和连接节点形成集群。

## MongoDB

- 定义：mongoDB 是一种文档性的数据库。先解释一下文档的数据库，即可以存放xml、json、bson类型系那个的数据。

这些数据具备自述性（self-describing），呈现分层的树状数据结构。redis可以用hash存放简单关系型数据。

mongoDB 存放json格式数据。

- 适合场景：事件记录、内容管理或者博客平台，比如评论系统。

### 持久化原理

mongodb与mysql不同，mysql的每一次更新操作都会直接写入硬盘，但是mongo不会，做为内存型数据库，数据操作会先写入内存，然后再会持久化到硬盘中去，那么mongo是如何持久化的呢
mongodb在启动时，专门初始化一个线程不断循环（除非应用crash掉），用于在一定时间周期内来从defer队列中获取要持久化的数据并写入到磁盘的journal(日志)和mongofile(数据)处，当然因为它不是在用户添加记录时就写到磁盘上，所以按mongodb开发者说，它不会造成性能上的损耗，因为看过代码发现，当进行CUD操作时，记录(Record类型)都被放入到defer队列中以供延时批量（groupcommit）提交写入，但相信其中时间周期参数是个要认真考量的参数，系统为90毫秒，如果该值更低的话，可能会造成频繁磁盘操作，过高又会造成系统宕机时数据丢失过。

2：什么是NoSQL数据库？NoSQL和RDBMS有什么区别？在哪些情况下使用和不使用NoSQL数据库？
NoSQL是非关系型数据库，NoSQL = Not Only SQL。
关系型数据库采用的结构化的数据，NoSQL采用的是键值对的方式存储数据。
在处理非结构化/半结构化的大数据时；在水平方向上进行扩展时；随时应对动态增加的数据项时可以优先考虑使用NoSQL数据库。

在考虑数据库的成熟度；支持；分析和商业智能；管理及专业性等问题时，应优先考虑关系型数据库。

3.MySQL和MongoDB之间最基本的区别是什么？
关系型数据库与非关系型数据库的区别，即数据存储结构的不同。

4.MongoDB的特点是什么？
（1）面向文档（2）高性能（3）高可用（4）易扩展（5）丰富的查询语言

5.MongoDB支持存储过程吗？如果支持的话，怎么用？
MongoDB支持存储过程，它是javascript写的，保存在db.system.js表中。

6.如何理解MongoDB中的GridFS机制，MongoDB为何使用GridFS来存储文件？
GridFS是一种将大型文件存储在MongoDB中的文件规范。使用GridFS可以将大文件分隔成多个小文档存放，这样我们能够有效的保存大文档，而且解决了BSON对象有限制的问题。

7.为什么MongoDB的数据文件很大？
MongoDB采用的预分配空间的方式来防止文件碎片。

8.当更新一个正在被迁移的块（Chunk）上的文档时会发生什么？
更新操作会立即发生在旧的块（Chunk）上，然后更改才会在所有权转移前复制到新的分片上。

9.MongoDB在A:{B,C}上建立索引，查询A:{B,C}和A:{C,B}都会使用索引吗？
不会，只会在A:{B,C}上使用索引。

10.如果一个分片（Shard）停止或很慢的时候，发起一个查询会怎样？
如果一个分片停止了，除非查询设置了“Partial”选项，否则查询会返回一个错误。如果一个分片响应很慢，MongoDB会等待它的响应。

## 文档型数据库

- MongoDB与EleasticSearch相同点：

1、都是以json格式管理数据的nosql数据库。
2、都支持CRUD操作。
3、都支持聚合和全文检索。
4、都支持分片和复制。
5、都支持阉割版的join操作。
6、都支持处理超大规模数据。
7、目前都不支持事务或者叫支持阉割版的事务。

- 不同点：

1、开发语言不同：ES的Java语言(restful)，Mongo是C++语言(driver)，从开发角度来看，ES对Java更方便
2、分片方式：ES是hash，Mongo是range和hash
3、分布式：ES的主副分片自动组合和配置，Mongo需要手动配置集群“路由+服务配置+sharding”
4、索引：ES自建倒排索引，检索力度强，Mongo手动创建索引（B树），不支持倒排索引；es所有字段自动索引，mongodb的字段需要手动索引。
5、检索字段：ES全文检索，可用的检索插件较多，Mongo对索引字段个数有限制，全文检索效率低乃至不采用

- 倒排索引

倒排索引源于实际应用中需要**根据属性的值**来查找记录。这种索引表中的每一项都包括**一个属性值和具有该属性值的各记录的地址**。由于不是由记录来确定属性值，而是由属性值来确定记录的位置，因而称为倒排索引(inverted index) [参考](https://www.cnblogs.com/fly1988happy/archive/2012/04/01/2429000.html)

# 通信

## HTTP

### Http请求的过程

#### 概述

1. 浏览器进行DNS域名解析，得到对应的IP地址
2. 根据这个IP，找到对应的服务器建立连接（三次握手）
3. 建立TCP连接后发起HTTP请求（一个完整的http请求报文）
4. 服务器响应HTTP请求，浏览器得到html代码（服务器如何响应）
5. 浏览器解析html代码，并请求html代码中的资源（如js、css、图片等）
6. 浏览器对页面进行渲染呈现给用户
7. 服务器关闭TCP连接（四次挥手）

#### DNS解析

1. 搜索浏览器自身的DNS缓存（缓存时间比较短，大概只有1分钟，且只能容纳1000条缓存）
2. 搜索系统自身的DNS缓存
3. 尝试从 hosts文件里面去找
4. 向本地配置的首选DNS服务器发起域名解析请求

*DNS优化两个方面：DNS缓存、DNS负载均衡*

## TCP

**为什么连接的时候是三次握手，关闭的时候却是四次握手？**

因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，"你发的FIN报文我收到了"。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。

**TCP建立连接的过程采用三次握手，已知第三次握手报文的发送序列号为1000，确认序列号为2000，请问第二次握手报文的发送序列号和确认序列号分别为？**
参考上面TCP连接建立的图。
客户端：发送X
服务端：发送Y， 确认X+1
客户端：发送X+1（1000），确认Y+1（2000）
可以反推第二次为1999,确认1000

**如何保证TCP连接的可靠性**

1. 校验和：发送的数据包的二进制相加然后取反，目的是检测数据在传输过程中的任何变化。如果收到段的检验和有差错，TCP将丢弃这个报文段和不确认收到此报文段。 
2. 确认应答+序列号：TCP给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。 
3. 超时重传：当TCP发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。 
4. 流量控制：TCP连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方的数据，能提示发送方降低发送的速率，防止包丢失。TCP使用的流量控制协议是可变大小的滑动窗口协议。  
5. 拥塞控制：当网络拥塞时，减少数据的发送。       

## RabbitMQ

### 组成部分

- Broker：消息队列服务进程。此进程包括两个部分：Exchange和Queue。
- Exchange：消息队列交换机。按一定的规则将消息路由转发到某个队列。
- Queue：消息队列，存储消息的队列。
- Producer：消息生产者。生产方客户端将消息同交换机路由发送到队列中。
- Consumer：消息消费者。消费队列中存储的消息。

**Exchange的四种类型**

- **Direct**：绑定一个队列，生产者发送消息给Exchange会指定一个Routing Key，要求**该消息与一个特定的路由键完全匹配**。简单点说就是一对一的，点对点的发送。它是完全匹配、单播的模式。
- **Fanout** ：发送到交换机的消息都会被转发到与该交换机绑定的所有队列上。很像子网广播
- **Topic**：通过模式匹配分配消息的路由键属性
- **Headers** ：路由不是用routingKey进行路由匹配，而是在匹配请求头中所带的键值进行路由

### 如何保证消息不丢失

消息丢失主要分为 生产者丢失消息、消息列表丢失消息、消费者丢失消息。

##### 生产者丢失消息

RabbitMQ 提供 **transaction** 和 **confirm** 模式来确保生产者不丢消息。

- **transaction 机制**：发送消息前，开启事务(channel.txSelect)，然后发送消息，如果发送过程中出现什么异常，事务就会回滚（channel.txRollback()），如果发送成功则提交事务channel.txCommit()。事务卡顿会导致后面无法发送，官方说加入事务机制MQ会降速250倍。

- **confirm(发送方确认模式)模式用的居多**：一旦 channel 进入 confirm 模式，所有在该信道上发布的消息都将会被指派一个从1开始的唯一的ID，一旦消息被投递到所有匹配的队列之后，RabbitMQ 就会发送一个包含消息的唯一ID 的 ACK给生产者，这就使得生产者知道消息已经正确到达目的队列了，如果 RabbitMQ 没能处理该消息，则会发送一个 Nack (not acknowledged) 消息给你，你可以进行重试操作。

发送方确认模式是异步的，生产者应用程序在等待确认的同时，可以继续发送消息。当确认消息到达生产者应用程序，生产者应用程序的回调方法就会被触发来处理确认消息。

#####  消息列表 丢失消息

处理消息队列丢数据的情况，一般是开启持久化磁盘的配置。这个持久化配置可以和**confirm** 机制配合使用，你可以在消息持久化磁盘后，再给生产者发送一个 Ack 信号。这样，如果消息持久化磁盘之前，**RabbitMQ** 挂了后生产者收不到Ack信号，生产者会自动重发。

通过如下持久化设置，即使 RabbitMQ 挂了重启后也能恢复数据。

1. **durable** = true, 将 queue 的持久化设置为 true，则代表是一个持久的队列
2. 发送消息的时候将 **deliveryMode**=2（1：非持久化  2：持久化）

关于持久化其实是个权衡问题，持久化可能会导致系统QPS下降，所以一般仅对关键消息作持久化处理（根据业务重要程度），且应该保证关键消息的持久化不会导致系统性能瓶颈。

##### 消费者丢失消息

消费者丢失消息：消费者丢数据一般是因为**采用了自动确认消息模式**，改为手动确认消息即可！

消费者在收到消息之后，处理消息之前，会**自动回复**RabbitMQ已收到消息；如果这时处理消息失败，就会丢失该消息。

**解决方案**：处理消息成功后，手动回复确认消息。消费者跟消息队列的连接不中断，RabbitMQ 给了 Consumer 足够长的时间来处理消息，保证数据的最终一致性。

**注意点**：

1. 消费者接收到消息却没有确认消息，连接也未断开，则 RabbitMQ 认为该消费者繁忙，将不会给该消费者分发更多的消息。
2. 如果消费者接收到消息，在确认之前断开了连接或取消订阅，RabbitMQ 会认为消息没有被分发，然后重新分发给下一个订阅的消费者，这时可能存在消息重复消费的隐患，需要去重！

###  如何避免消息重复投递或重复消费

消息重复消费的场景大概可以分为 生产者端重复消费 和 消费者端重复消费，解决办法是是通过**幂等性**来保证重复消费的消息不对结果产生影响即可。

1. 消息生成时 RabbitMQ 内部 对每个生产的消息生成个 inner-msg-id，作为去重和幂等的依据（消息投递失败并重传），避免重复的消息进入队列。
2. 消息消费时 要求消息体中必须要有一个 bizId（对于同一业务全局唯一，如支付 ID、订单 ID、帖子 ID 等）作为去重的依据，避免同一条消息被重复消费。
3. 在 RocketMQ 中生产者发送消息前询问 RocketMQ 信息是否已发送过，或者通过Redis记录已查询记录。不过最好的还是直接在消费端去重消费。

### 如何保证消息顺序执行

##### 乱序情况

1. 一个 queue，有多个 consumer 去消费，每个 consumer 的执行时间是不固定的，无法保证先读到消息的 consumer 一定先完成操作。

2. 一个 queue 对应一个 consumer，但是 consumer 里面进行了**多线程**消费，这样也会造成消息消费顺序错误。

##### 解决乱序

1. 拆分多个 queue，每个 queue 一个 consumer，将三个有先后顺序的消息根据用户订单id 哈希后发送到同一个queue中，来保证消息的先后性。当然这样会造成吞吐量下降。

2. 一个 queue 对应一个 consumer，在 consumer 内部根据ID映射到不同内存队列，然后用内存队列做排队 分发给底层不同的 worker 来处理

### RabbitMQ 的集群

RabbitMQ 是基于主从（非分布式）做高可用性的。RabbitMQ 有三种模式：**单机模式、普通集群模式、镜像集群模式**。

##### 普通集群模式

在 N 台机器上启动 N 个 RabbitMQ 实例。创建的 queue 只会放在一个 RabbitMQ 实例上，但每个MQ实例都 同步 queue 的元数据（元数据可以认为是 queue 的一些配置信息，通过元数据，可以找到 queue 所在实例）。消费时如果连接到了另外一个实例，那么那个实例会从 queue 所在实例上拉取数据过来。让集群中多个节点来服务某个 queue 的读写操作来提高吞吐量。

##### 镜像集群模式

RabbitMQ 的高可用模式，在镜像集群模式下，你创建的 queue无论元数据还是 queue 里的消息都会存在于多个实例上，每个 RabbitMQ 节点都有这个 queue 的全部数据的。写消息到 queue 的时候都会自动把消息同步到多个实例的 queue 上。RabbitMQ 有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候是可以要求数据同步到所有节点的，也可以要求同步到指定数量的节点，再次创建 queue 的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。

1. **优点**在于任何一个机器宕机了其它节点还包含了这个 queue 的完整数据，别的 consumer 都可以到其它节点上去消费数据。
2. **缺点**在于消息需要同步到所有机器上，导致网络带宽压力和消耗很重。也是每个节点都放这个 queue 的完整数据。

## Kafka

### 组成部分

- Producer ：消息生产者，就是向 kafka broker 发消息的客户端。
- Consumer ：消息消费者，向 kafka broker 取消息的客户端。
- Topic ：可以理解为一个队列，一个 Topic 又分为一个或多个分区
- Broker ：一台 kafka 服务器就是一个 broker。一个集群由多个 broker 组成。一个 broker 可以容纳多个 topic。
- Partition：为了实现扩展性，一个非常大的 topic 可以分布到多个 broker上，每个 partition 是一个有序的队列。partition 中的每条消息都会被分配一个有序的id（offset）。将消息发给 consumer，kafka 只保证按一个 partition 中的消息的顺序，不保证一个 topic 的整体（多个 partition 间）的顺序。
- Segment：Partition在物理上由多个Segment数据文件组成，每个Segment数据文件都大小相等，按顺序读写

### 与RabbitMQ区别

RabbitMQ：用于实时的，对可靠性要求较高的消息传递上。

kafka：优势主要体现在吞吐量上，主要用于处理活跃的流式数据，大数据量的数据处理上。

# 分布式

## CAP定理

一个分布式系统最多只能同时满足cap中的两项

- 一致性（Consistency）：所有节点在同一时间的数据完全一致
- 可用性（Availability）：服务在正常响应时间内一直可用
- 分区容错性（Partition tolerance）：分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性或可用性的服务

对于CAP理论中，分布式系统要保障整体的服务，因此分区容错性必然要保障

**CP：** 有些系统中一致性是本质要求，例如Redis分布式存储，ZooKeeper任何时候访问ZK都可以获得一致性的结果。极端情况下可能丢弃一些请求，从而保障一致性。 

**AP：** 比如有的网页对一致性要求不是那么高，对商品价格进行更改，但是要保障用户仍然能顺利的访问网页。但是会在付款的时候对价格进行再次验证。

## Base理论

指基本可用（Basically Available）、软状态（ Soft State）、最终一致性（ Eventual Consistency）。

BASE理论是对 CAP 中的一致性和可用性进行一个权衡的结果，通常的做法会选择AP舍弃C（舍弃强一致性但保证最终一致性）

## 一致性协议与算法

- **2PC（二阶段提交）**

  - 请求阶段
    在请求阶段，协调者将通知事务参与者准备提交或取消事务，然后进入表决过程。
    在表决过程中，参与者将告知协调者自己的决策：同意（事务参与者本地作业执行成功）或取消（本地作业执行故障）。
  - 提交阶段
    在该阶段，协调者将基于第一个阶段的投票结果进行决策：提交或取消。
    当且仅当所有的参与者同意提交事务协调者才通知所有的参与者提交事务。

- **3PC（三阶段提交）**

  三阶段提交针对两阶段提交做了改进：

  - 在第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与节点的状态是一致的。
  - 引入超时机制。在2PC中，只有协调者拥有超时机制，3PC同时在协调者和参与者中都引入超时机制。

- **TCC（补偿事务）**

  - Try：资源预留
  - Confirm：确认执行业务操作
  - Cancel：取消Try阶段预留的业务资源

  常用TCC开源框架：ByteTCC、Himly、TCC-transaction、seata

  参考文档：

  https://www.cnblogs.com/jajian/p/10014145.html

  http://www.tianshouzhi.com/api/tutorials/distributed_transaction/388



- Paxos：《优雅的Paxos算法》

- Raft ：《[Raft 一致性算法](https://www.zhihu.com/search?q=Raft+一致性算法&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A1795787642})》

- Gossip：《[Gossip Visualization](https://www.zhihu.com/search?q=Gossip+Visualization&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A1795787642})》

## 分布式锁

### 1. Redisson实现Redis分布式锁

Redis 有「互斥」的能力，我们可以使用 SETNX

- **死锁问题**：设置过期时间，SET $lock_key $unique_id EX $expire_time NX
- **过期时间不好评估，锁提前过期**：守护线程（watch dog），自动续期
- **释放了别人的锁**：锁写入唯一标识，释放锁先检查标识，再释放（判断和释放使用Lua保证原子操作）
- **可重入加锁机制**：重入时客户端1的加锁次数，累加1，释放时递减1，如果发现是0，删除锁

### 2. RedLock

Redlock 的方案基于 2 个前提：

1. 不再需要部署**从库**和**哨兵**实例，只部署**主库**
2. 但主库要部署多个，官方推荐至少 5 个实例

Redlock 的方案基于 2 个前提：

1. 客户端在多个 Redis 实例上申请加锁
2. 必须保证大多数节点加锁成功
3. 多数节点加锁的总耗时，要小于锁设置的过期时间
4. 释放锁，要向全部节点发起释放锁请求

### 3. Zookeeper

1. 客户端 1 和 2 都尝试创建「临时节点」，例如 /lock
2. 假设客户端 1 先到达，则加锁成功，客户端 2 加锁失败
3. 客户端 1 操作共享资源
4. 客户端 1 删除 /lock 节点，释放锁

Zookeeper 的优点：

1. zookeeper「临时节点」不需要考虑锁的过期时间
2. watch 机制，加锁失败，可以 watch 等待锁释放，实现乐观锁

缺点：

1. 性能不如 Redis
2. 部署和运维成本高
3. 客户端与 Zookeeper 的长时间失联，锁被释放问题

## SOA和微服务

SOA（Service Oriented Architecture）“面向服务的架构”:他是一种设计方法，其中包含多个服务， 服务之间通过相互依赖最终提供一系列的功能。一个服务 通常以独立的形式存在于操作系统进程中。各个服务之间 通过网络调用。

微服务架构:其实和 SOA 架构类似，微服务是在 SOA 上做的升华，微服务架构强调的一个重点是“业务需要彻底的组件化和服务化”，原有的单个业务系统会拆分为多个可以独立开发、设计、运行的小应用。这些小应用之间通过服务完成交互和集成。

# 数据结构

## 链表

单链表的特点

- 链表增删元素的时间复杂度为O(1),查找一个元素的时间复杂度为 O(n);
- 单链表不用像数组那样预先分配存储空间的大小，避免了空间浪费
- 单链表不能进行回溯操作，如：只知道链表的头节点的时候无法快读快速链表的倒数第几个节点的值。

## B树、B+树

**平衡二叉树**

是基于二分法的策略提高数据的查找速度的二叉树的数据结构，用这个树形结构的数据减少无关数据的检索，大大的提升了数据检索的速度（AVL：高度平衡二叉树）。（特点：

（1）非叶子节点最多拥有两个子节点；

（2）非叶子节值大于左边子节点、小于右边子节点；

（3）树的左右两边的层级数相差不会大于1;

（4）没有值相等重复的节点;

**B树**

- 根节点至少有两个子节点（所以B树不一定是二叉树）
- 每个节点有M-1个key，并且以升序排列
- 位于M-1和M key的子节点的值位于M-1 和M key对应的Value之间
- 其它节点至少有M/2个子节点

B树相对于平衡二叉树的不同是，每个节点包含的关键字增多了，特别是在B树应用到数据库中的时候，数据库充分利用了磁盘块的原理（磁盘数据存储是采用块的形式存储的，每个块的大小一般为4K，每次IO进行数据读取时，同一个磁盘块的数据可以一次性读取出来）把节点大小限制和充分使用在磁盘快大小范围；把树的节点关键字增多后树的层级比原来的二叉树少了，减少数据查找的次数和复杂度;

**B+树**

B+树是B树的一个升级版，相对于B树来说B+树更充分的利用了节点的空间，让查询速度更加稳定，其速度完全接近于二分法查找。为什么说B+树查找的效率要比B树更高、更稳定；我们先看看两者的区别

（1）B+跟B树不同B+树的非叶子节点不保存关键字记录的指针，这样使得B+树每个节点所能保存的关键字大大增加；

（2）B+树叶子节点保存了父节点的所有关键字和关键字记录的指针，每个叶子节点的关键字从小到大链接；

（3）B+树的根节点关键字数量和其子节点个数相等;

（4）B+的非叶子节点只进行数据索引，不会存实际的关键字记录的指针，所有数据地址必须要到叶子节点才能获取到，所以每次数据查询的次数都一样；

特点：

在B树的基础上每个节点存储的关键字数更多，树的层级更少所以查询数据更快，所有指关键字指针都存在叶子节点，所以每次查找的次数都相同所以查询速度更稳定;

## 红黑树

R-B Tree，全称是Red-Black Tree，又称为“红黑树”，它一种特殊的二叉查找树。红黑树的每个节点上都有存储位表示节点的颜色，可以是红(Red)或黑(Black)。

红黑树的特性:

（1）每个节点或者是黑色，或者是红色。
（2）根节点是黑色。
（3）每个叶子节点（NIL）是黑色。 [注意：这里叶子节点，是指为空(NIL或NULL)的叶子节点！]
（4）如果一个节点是红色的，则它的子节点必须是黑色的。
（5）从一个节点到该节点的子孙节点的所有路径上包含相同数目的黑节点。

# 部署相关

## Docker

## k8s

## Nginx

**Nginx是如何处理高并发的**

一个主进程，多个工作进程，每个工作进程可以处理多个请求，每进来一个request，会有一个worker进程去处理。但不是全程的处理，处理到可能发生阻塞的地方，比如向上游（后端）服务器转发request，并等待请求返回。那么，这个处理的worker继续处理其他请求，而一旦上游服务器返回了，就会触发这个事件，worker才会来接手，这个request才会接着往下走。由于web server的工作性质决定了每个request的大部份生命都是在网络传输中，实际上花费在server机器上的时间片不多。这是几个进程就解决高并发的秘密所在。即@skoo所说的webserver刚好属于网络io密集型应用，不算是计算密集型。

LVS与Nginx

# 设计模式

## 六大原则

开闭原则：对扩展开放，对修改关闭，多使用抽象类和接口。

里氏替换原则：基类可以被子类替换，使用抽象类继承,不使用具体类继承。

依赖倒转原则：要依赖于抽象，不要依赖于具体，针对接口编程,不针对实现编程。

接口隔离原则：使用多个隔离的接口，比使用单个接口好，建立最小的接口。

迪米特法则：一个软件实体应当尽可能少地与其他实体发生相互作用，通过中间类建立联系。

合成复用原则：尽量使用合成/聚合，而不是使用继承。



合成/聚合复用原则是在一个新的对象里面使用一些已有的对象，使之成为新对象的一部分；新的对象通过向这些对象的委派达到复用已有功能的目的。由于合成或聚合可以将已有对象纳入到新对象中，使之成为新对象的一部分，因此新对象可以调用已有对象的功能。这样做的好处有

（1） 新对象存取成分对象的唯一方法是通过成分对象的接口。

（2） 这种复用是黑箱复用，因为成分对象的内部细节是新对象看不见的。

（3） 这种复用支持包装。

（4） 这种复用所需的依赖较少。

（5） 每一个新的类可以将焦点集中到一个任务上。

（6） 这种复用可以再运行时间内动态进行，新对象可以动态地引用与成分对象类型相同的对象。

# 计算机原理



- 原码：符号位加上真值的绝对值, 即用第一位表示符号, 其余位表示值
- 反码：正数的反码是其本身，负数的反码是在原码的基础上, 符号位不变，其余各个位取反（为了正确计算负数，因为原码不能用于计算负数）
- 补码：正数的补码是其本身，负数的补码是在反码的基础上+1（反码不能解决负数跨零问题，在计算机当中都是使用补码来进行计算和存储的）