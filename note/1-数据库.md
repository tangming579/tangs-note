# 数据库

## 概念

**三大范式**

- 1NF：符合1NF的关系中的每个属性都不可再分

  要求属性具有原子性，不可再分解

- 2NF：2NF在1NF的基础之上，消除了非主属性对于码的部分函数依赖

  确保每一条记录都是独立的。记录的唯一性种数据保存在同一张数据库表中

- 3NF：3NF在2NF的基础之上，消除了非主属性对于码的传递函数依赖

  确保数据表中的每一列数据都和主键直接相关，而不能间接相关

### Sharding-JDBC

#### 功能

1） 数据分片：分库分表、读写分离、分片策略、分布式主键

2） 分布式事务：标准化事务接口、XA强一致性事务、柔性事务

3） 数据库治理：配置动态、服务治理、数据脱敏、链路追踪

#### 原理

```java
// 创建池化的数据源
PooledDataSource dataSource = new PooledDataSource ();
// 设置 MySQL Driver
dataSource.setDriver ("com.mysql.jdbc.Driver");
// 设置数据库 URL、用户名和密码
dataSource.setUrl ("jdbc:mysql://localhost:3306/test");
dataSource.setUsername("root");
dataSource.setPassword("root");
// 获取连接
Connection connection = dataSource.getConnection(); 
// 执行查询
PreparedStatement statement = connection.prepareStatement ("select * from user");
// 获取查询结果进行处理
ResultSet resultSet = statement.executeQuery();
while (resultSet.next()) {
	…
} 
// 关闭资源
statement.close();
resultSet.close();
connection.close();
```

`DataSource`、`Connection`、`Statement` 、`ResultSet` 等 API 接口，直接操作数据库即可。所以如果想在 JDBC 层面实现数据分片就必须对现有的 API 进行功能拓展，而 Sharding-JDBC 正是基于这种思想，重写了 JDBC 规范并完全兼容了 JDBC 规范。

- `ShardingDataSource`：持有对数据源和分片规则，可以通过 getConnection 方法获取 ShardingConnection 连接
- `ShardingConnection`：创建 ShardingStatement 和  ShardingPreparedStatement；获取真正的数据库连接，事务提交功能
- `ShardingStatement`：完成 SQL  解析、路由、改写；进行 SQL 执行；最后对结果进行合并处理。
- `ShardingResultSet `：获取分片结果集

#### 执行流程

1. 解析sql，获取片键值，比如order_id
2. Sharding-JDBC通过规则配置，判断往哪个表里插。
3. 于是Sharding-JDBC根据order_id的值改写sql语句，改写后的SQ语句是真实所要执行的SQL语句。
4. 执行改写后的真实sql语句
5. 将所有真正执行sql的结果进行汇总合并，返回

## MySQL

### 数据库优化

**优化顺序**

sql语句优化 -> 索引优化 -> 加缓存 -> 读写分离 -> 分区 -> 分布式数据库（垂直切分）-> 水平切分 

**设计表时要注意**

-  表字段避免null值出现，null值很难查询优化且占用额外的索引空间，推荐默认数字0代替null。
-  尽量使用INT而非BIGINT，如果非负则加上UNSIGNED（这样数值容量会扩大一倍），当然能使用TINYINT、SMALLINT、MEDIUM_INT更好。
-  使用枚举或整数代替字符串类型
-  尽量使用TIMESTAMP而非DATETIME
-  单表不要有太多字段，建议在20以内
-  用整型（unsigned int）来存IP（1.方便分段查询；2.节省空间）

**索引**

-  索引并不是越多越好，要根据查询有针对性的创建，考虑在WHERE和ORDER BY命令上涉及的列建立索引，可根据EXPLAIN来查看是否用了索引还是全表扫描
-  应尽量避免在WHERE子句中对字段进行NULL值判断，否则将导致引擎放弃使用索引而进行全表扫描
-  值分布很稀少的字段不适合建索引，例如"性别"这种只有两三个值的字段
-  字符字段只建前缀索引
-  字符字段最好不要做主键
-  不用外键，由程序保证约束
-  尽量不用UNIQUE，由程序保证约束
-  使用多列索引时主意顺序和查询条件保持一致，同时删除不必要的单列索引

**简言之就是使用合适的数据类型，选择合适的索引**

1.选择合适的数据类型

- （1）使用可存下数据的最小的数据类型，整型 < date,time < char,varchar < blob
- （2）使用简单的数据类型，整型比字符处理开销更小，因为字符串的比较更复杂。如，int类型存储时间类型，bigint类型转ip函数
- （3）使用合理的字段属性长度，固定长度的表会更快。使用enum、char而不是varchar
- （4）尽可能使用not null定义字段
- （5）尽量少用text，非用不可最好分表

 2.选择合适的索引列

- （1）查询频繁的列，在where，group by，order by，on从句中出现的列
- （2）where条件中<，<=，=，>，>=，between，in，以及like 字符串+通配符（%）出现的列
- （3）长度小的列，索引字段越小越好，因为数据库的存储单位是页，一页中能存下的数据越多越好
- （4）离散度大（不同的值多）的列，放在联合索引前面。查看离散度，通过统计不同的列值来实现，count越大，离散程度越高：

**sql的编写需要注意优化**

-  使用limit对查询结果的记录进行限定
-  避免select *，将需要查找的字段列出来
-  使用连接（join）来代替子查询
-  拆分大的delete或insert语句
-  可通过开启慢查询日志来找出较慢的SQL
-  不做列运算：SELECT id WHERE age + 1 = 10，任何对列的操作都将导致表扫描，它包括数据库教程函数、计算表达式等等，查询时要尽可能将操作移至等号右边
-  sql语句尽可能简单：一条sql只能在一个cpu运算；大语句拆小语句，减少锁时间；一条大sql可以堵死整个库
-  OR改写成IN：OR的效率是n级别，IN的效率是log(n)级别，in的个数建议控制在200以内
-  不用函数和触发器，在应用程序实现
-  避免%xxx式查询
-  少用JOIN
-  使用同类型进行比较，比如用'123'和'123'比，123和123比
-  尽量避免在WHERE子句中使用!=或<>操作符，否则将引擎放弃使用索引而进行全表扫描
-  对于连续数值，使用BETWEEN不用IN：SELECT id FROM t WHERE num BETWEEN 1 AND 5
-  列表数据不要拿全表，要使用LIMIT来分页，每页数量也不要太大

**MyISAM和InnoDB的区别**

1. InnoDB支持事务，MyISAM不支持，对于InnoDB每一条SQL语言都默认封装成事务，自动提交，这样会影响速度，所以最好把多条SQL语言放在begin和commit之间，组成一个事务； 
2. InnoDB支持外键，而MyISAM不支持。对一个包含外键的InnoDB表转为MYISAM会失败； 
3. InnoDB不保存表的具体行数，执行select count(*) from table时需要全表扫描。而MyISAM用一个变量保存了整个表的行数，执行上述语句时只需要读出该变量即可，速度很快； 
4. Innodb不支持全文索引，而MyISAM支持全文索引，查询效率上MyISAM要高； 
5. 锁机制不同: InnoDB 为行级锁，myisam 为表级锁。 

**索引查找、索引扫描**

全表扫描：读取表中所有的行
索引扫描：类似全表扫描
索引查找：定位到索引指向的局部位置

- 隐式转换容易从索引查找变成索引扫描

- where子句中的谓词不是联合索引的第一列对于联合索引最左边一列存有统计信息，其他列sqlserver不存统计信息

- where 子句里串联会导致索引失效 where A+B = ... (索引为A，B联合索引)

- =,>,<,>=,<=,between,以及部分like(like'%XXX') 
- 两个相关联的表的格式不一致

**什么是全表扫描**

全表扫描 (又称顺序扫描) 就是在数据库中进行逐行扫描，顺序读取表中的每一行记录，然后检查各个列是否符合查询条件。这种扫描是已知最慢的，因为需要进行大量的磁盘 I/O，而且从磁盘到内存的传输开销也很大。

**回表**

由于辅助索引只存储主键的值,如果使用辅助索引搜索数据就必须先从辅助索引取到主键的值,再使用主键的值去主键索引上查询,直到找到叶子节点上的数据返回

如果查询的列本身就存在于索引中，那么即使使用辅助索引，一样也是不需要回表的。

**联合索引**

联合索引是指对表上的多个列进行索引，联合索引也是一棵B+树，不同的是联合索引的键值数量不是1，而是大于等于2，联合索引的查询要尽量符合最左匹配原则

优化：在联合索引中将选择性最高的列放在索引最前面。

**覆盖索引**

SQL只需要通过索引就可以返回查询所需要的数据，而不必通过二级索引查到主键之后再去查询数据

判断标准：使用explain，可以通过输出的extra列来判断，对于一个索引覆盖查询，显示为**using index**

### 日志

- redo log：重做日志，记录数据改变之后的值（InnoDB事务日志）

- undo log：撤销日志，记录事务发生前数据的值（InnoDB事务日志）

- binlog：归档日志，记录日志sql语句，用于数据库基于时间点的还原，主从复制（Server层面日志）
- errorlog：错误日志
- slow query log：慢查询日志

#### redo

- 一是内存中重做日志缓冲 (redo log buffer)，是易失的，在内存中
- 二是重做日志文件 (redo log file)，是持久的，保存在磁盘中

**事务开始之后**就产生redo log，整体流程

- 第一步：先将原始数据从磁盘中读入内存中来，修改数据的内存拷贝
- 第二步：生成一条重做日志并写入redo log buffer，记录的是数据被修改后的值
- 第三步：当事务commit时，将redo log buffer中的内容刷新到 redo log file，对 redo log file采用追加写的方式
- 第四步：定期将内存中修改的数据刷新到磁盘中

> 例如某一事务的事务序号为T1，其对数据X进行修改，设X的原值是5，修改后的值为15，那么
>
> Undo日志为<T1, X, 5>
>
> Redo日志为<T1, X, 15>。

#### undo

- 产生：**事务开始之前**，将当前事务的版本生成undo log，undo 也会产生 redo 来保证undo log的可靠性
- 释放：当事务提交之后，undo log并不能立马被删除，而是放入待清理的链表，由purge线程判断定是否可以清理undo log的日志空间

#### binlog

逻辑格式的日志，可以简单认为就是执行过的事务中的sql语句。但又不完全是sql语句这么简单，而是包括了执行的sql语句（增删改）反向的信息

- 产生：**事务提交的时候**，一次性将事务中的sql语句（一个事物可能对应多个sql语句）按照一定的格式记录到binlog中。
- 释放：在生成时间超过expire_logs_days配置的天数之后，会被自动删除

binlog与redo log区别：

- redo log是保证事务的持久性的，是事务层面的，binlog作为还原的功能，是数据库层面的
- redo log是物理日志，是数据页面的修改之后的物理记录，binlog是逻辑日志，记录的是sql语句
- 两者日志产生的时间，可以释放的时间，在可释放的情况下清理机制，都是完全不同的
- 恢复数据时候的效率，基于物理日志的redo log恢复数据的效率要高于语句逻辑日志的binlog

### InnoDB逻辑存储结构

所有的数据都被存放在一个空间中，被称为表空间，表空间又分为段、区、页

- 段：数据段（B+树的叶子节点）、索引段（B+树的非叶子节点）、回滚段
- 区：由连续的页组成的空间，默认1M，一个区默认有64个页
- 页：InnoDB磁盘管理的最小单位，默认16KB，可通过innodb_page_size字段修改为4K、8K、16K
- 行：具体数据

### 事务

**事务的ACID**

1. 原子性：整个事务中的所有操作，要么全部完成，要么全部不完成 

   （由redo/undo log日志保证，它记录了需要回滚的日志信息，事务回滚时撤销已经执行成功的sql）

2. 一致性：事务前后数据的完整性必须保持一致。另一种说法：保证事务只能把数据库从一个有效（正确）的状态“转移”到另一个有效（正确）的状态

   （原子性、隔离性、持久性都是为了最终实现一致性）

3. 隔离性：同一时间仅有一个请求用于同一数据（MVCC来保证）

4. 持久性：在事务完成以后，该事务对数据库所作的更改便持久的保存在数据库之中，并不会被回滚

   （由内存+redo log来保证，mysql修改数据同时在内存和redo log记录这次操作，事务提交的时候通过redo log刷盘，宕机的时候可以从redo log恢复）

**事务的隔离级别**

1. Read Uncommitted（未提交读） ：事务中的修改，即使没有提交，其他事务也可以看得到，会导致“脏读”、“幻读”和“不可重复读取;
2. READ COMMITTED （提交读）：大多数主流数据库的默认事务等级，保证了一个事务不会读到另一个并行事务已修改但未提交的数据，避免了“脏读”，但不能避免“幻读”和“不可重复读取”。该级别适用于大多数系统。
3. REPEATABLE READ（重复读） ：保证了一个事务不会修改已经由另一个事务读取但未提交（回滚）的数据。避免了“脏读取”和“不可重复读取”的情况，但不能避免“幻读”，但是带来了更多的性能损失。
4. Serializable （串行化）：最严格的级别，事务串行执行，资源消耗最大；

脏读：读取了另一个事务未提交的数据

不可重复读：读取一次，在第二次**读**之前更新了这个数据导致两次数据不同。

幻读：读取一次，在读第二次之前insert或者是delete，导致读取的**记录数**不同

​		   综上，不可重复读针对的是同一数据两次结果不同，幻读针对的是一片数据数量不同。

**锁的类型**

- 基于锁的属性分类：共享锁（S锁）、排他锁（X锁）。

- 基于锁的粒度分类：表锁、行锁、记录锁、间隙锁、临键锁。

- 基于锁的状态分类：意向共享锁、意向排它锁。

只有增、删、改才会加上排它锁，而只是查询并不会加锁，只能通过在select语句后显式加lock in share mode或者for update来加共享锁或者排它锁。

### MVCC

MVCC 多版本控制实现读取数据不用加锁， 可以让读取数据同时修改。修改数据时同时可读取。

最早的数据库系统，只有读读之间可以并发，读写，写读，写写都要阻塞。引入多版本之后，只有写写之间相互阻塞，其他三种操作都可以并行，这样大幅度提高了InnoDB的并发度。

MVCC 的实现依赖：隐藏字段、Read View、Undo log

- 隐藏字段

   InnoDB存储引擎在每行数据的后面添加了三个隐藏字段：

      1. DB_TRX_ID：表示最近一次对本记录行作修改（insert | update）的事务ID。
      2. DB_ROLL_PTR：回滚指针，指向当前记录行的undo log信息
      3. DB_ROW_ID：随着新行插入而单调递增的行ID（跟MVCC关系不大）

- Read View 

  > 在innodb 中每个SQL语句执行前都会创建一个快照（read_view）。快照主要保存了当前数据库系统中正处于活跃（没有commit）的事务的ID号（即trx_ids），其实简单的说这个快照中保存的是系统中当前不应该被本事务看到的其他事务id列表。

  1. low_limit_id：目前出现过的最大的事务ID+1，即下一个将被分配的事务ID

  2. up_limit_id：活跃事务列表trx_ids中最小的事务ID，如果trx_ids为空，则up_limit_id 为 low_limit_id

  3. trx_ids：Read View创建时其他未提交的活跃事务ID列表

     注意：Read View中trx_ids的活跃事务，不包括当前事务自己和已提交的事务（正在内存中）

  4.  creator_trx_id：当前创建事务的ID，是一个递增的编号 

- Undo log

  Undo log 主要用于记录数据被修改之前的日志，在表信息修改之前先会把数据拷贝到undo log 里，当事务进行回滚时可以通过undo log 里的日志进行数据还原。

```
  1. 如果 trx_id < up_limit_id, 那么表明“最新修改该行的事务”在“当前事务”创建快照之前就提交了，所以该记录行的值对当前事务是可见的。跳到步骤5。
  2. 如果 trx_id >= low_limit_id, 那么表明“最新修改该行的事务”在“当前事务”创建快照之后才修改该行，所以该记录行的值对当前事务不可见。跳到步骤4。
  3. 如果 up_limit_id <= trx_id < low_limit_id, 表明“最新修改该行的事务”在“当前事务”创建快照的时候可能处于“活动状态”或者“已提交状态”；所以就要对活跃事务列表trx_ids进行查找（源码中是用的二分查找，因为是有序的）：
     - 如果在活跃事务列表trx_ids中能找到 id 为 trx_id 的事务，表明①在“当前事务”创建快照前，“该记录行的值”被“id为trx_id的事务”修改了，但没有提交；或者②在“当前事务”创建快照后，“该记录行的值”被“id为trx_id的事务”修改了（不管有无提交）；这些情况下，这个记录行的值对当前事务都是不可见的，跳到步骤4；
     - 在活跃事务列表中找不到，则表明“id为trx_id的事务”在修改“该记录行的值”后，在“当前事务”创建快照前就已经提交了，所以记录行对当前事务可见，跳到步骤5。
  4. 在该记录行的 DB_ROLL_PTR 指针所指向的undo log回滚段中，取出最新的的旧事务号DB_TRX_ID, 将它赋给trx_id，然后跳到步骤1重新开始判断。
  5. 将该可见行的值返回。
```

select的时候InnoDB使用mvcc

select for update/select lock in share mode、/update/insert/delete的时候两阶段锁

### 主从复制

1. master开启bin-log功能，日志文件用于记录数据库的读写增删
2. 需要开启3个线程，master IO线程，slave开启 IO线程 SQL线程
3. Slave 通过IO线程连接master，并且请求某个bin-log，position之后的内容。
4. MASTER服务器收到slave IO线程发来的日志请求信息，io线程去将bin-log内容，position返回给slave IO线程。
5. slave服务器收到bin-log日志内容，将bin-log日志内容写入relay-log中继日志，创建一个master.info的文件，该文件记录了master ip 用户名 密码 master bin-log名称，bin-log position。
6. slave端开启SQL线程，实时监控relay-log日志内容是否有更新，解析文件中的SQL语句，在slave数据库中去执行。

## Redis

### 数据类型

| 结构类型         | 结构存储的值                                                 | 结构的读写能力                                               |
| ---------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| String           | 可以是字符串、整数或者浮点数                                 | 对整个字符串或者字符串的其中一部分执行操作；对整数和浮点数执行自增（increment）或者自减（decrement）操作 |
| List             | 一个链表，链表上的每个节点都包含了一个字符串                 | 从链表的两端推入或者弹出元素；根据偏移量对链表进行修剪（trim）；读取单个或者多个元素；根据值查找或者移除元素 |
| Set              | 包含字符串的无序收集器（unordered collection），并且被包含的每个字符串都是独一无二、各不相同的 | 添加、获取、移除单个元素；检查一个元素是否存在于集合中；计算交集、并集、差集；从集合里面随机获取元素 |
| Hash             | 包含键值对的无序散列表                                       | 添加、获取、移除单个键值对；获取所有键值对                   |
| ZSet（有序集合） | 字符串成员（member）与浮点数分值（score）之间的有序映射，元素的排列顺序由分值的大小决定 | 添加、获取、删除单个元素；根据分值范围（range）或者成员来获取元素 |

### 并发

#### 缓存穿透

大量请求了缓存和数据库中**都没有的数据**，每次都查询数据库，导致数据库压力过大

**解决方案**

1. 接口层增加校验，如用户鉴权校验，id做基础校验，id<=0的直接拦截
2. 加判断逻辑：将key-value对写为key-null，缓存有效时间可以设置短点，如30s（防止恶意攻击每次key不一样）
3. 设置过滤规则, 如布隆过滤器：布隆过滤器：将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，参考：https://www.cnblogs.com/wy123/p/11571215.html

#### 缓存击穿

一个key非常热点，在不停的扛着大并发，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞

**解决方案**

1. 热点数据永不过期
2. 使用互斥锁（mutex），思路就是只让一个线程构建缓存，其他线程等待构建缓存的线程执行完，重新从缓存获取数据

#### 缓存雪崩

某些原因，导致缓存**集体**过期（缓存击穿是单个key），如果此时出现高并发的请求出现，这些请求会全部指向数据库层，缓存层失去了对数据库层的保护，导致数据库承担绝大压力的情况。

**解决方案**

1. 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。
2. 如果缓存数据库是分布式部署，将热点数据均匀分布在不同搞得缓存数据库中。
3. 设置热点数据永远不过期。
4. 服务降级限流

### 与数据库一致性



### 过期策略

过期策略通常有一下三种：

- 定时删除：每个设置过期时间的key都需要创建一个定时器，到过期时间就会立即清除。该策略可以立即清除过期的数据，对内存很友好；但是会占用大量的CPU资源去处理过期的数据，从而影响缓存的响应时间和吞吐量。

- 惰性删除：只有当访问一个key时，才会判断该key是否已过期，过期则清除。该策略可以最大化地节省CPU资源，却对内存非常不友好。极端情况可能出现大量的过期key没有再次被访问，从而不会被清除，占用大量内存。

- 定期删除：每隔一段时间，会扫描一定数量的数据库的expires字典中一定数量的key，并清除其中已过期的key。该策略是前两者的折中方案。

  定期删除可以通过：

  - 第一、配置redis.conf 的hz选项，默认为10 （即1秒执行10次，100ms一次，随机抽取一些设置了过期时间的 key，检查其是否过期，如果过期就删除。） 
  - 第二、配置redis.conf的maxmemory最大值，当已用内存超过maxmemory限定时，就会触发主动清理策略（内存淘汰机制）

Redis中同时使用了惰性过期和定期过期两种过期策略。

### 内存满了怎么办

1. 增加内存
2. 内存淘汰策略
   - LRU，即：最近最少使用淘汰算法（Least Recently Used）。LRU是淘汰最长时间没有被使用的数据。其核心思想就是“如果数据最近被访问过，那么将来被访问的几率也更高”。基本思路：如果最近使用得比较多的数据就把他放到列表头部，依次更新，从列表尾部的依次淘汰，就是删除对应的key。
   - LFU，即：最不经常使用淘汰算法（Least Frequently Used）。LFU是淘汰一段时间内，使用次数最少的数据。它是基于“如果一个数据在最近一段时间内使用次数很少，那么在将来一段时间内被使用的可能性也很小”的思路。

### 分布式锁

### Redis 为什么快

- 基于内存实现
- 高效的数据结构
  - String：SDS（Simple Dynamic String）的结构体来保存字符串，不会在修改字符串的时候会重新分配内存：
    - 空间预分配：会额外分配未使用的空间
    - 惰性空间释放：SDS 缩短时，不会回收多余空间，而是记录下来。后续直接变更操作使用 free 中记录的空间
  - List 采用双端链表： O(1) 内就能获取到前后节点
  - 压缩列表：内存是连续分配的，遍历的速度很快
  - 跳表：增加了多级索引来提升查找效率
- IO 多路复用：多路复用技术，并发处理连接。采用了 epoll + 自己实现的简单的事件框架
- 全局 Hash 字典：Redis 整体就是一个哈希表来保存所有的键值对，无论数据类型是 5 种的任意一种

### Redis 多线程

**Redis6.0 之前为什么一直不使用多线程？**

Redis使用单线程的可维护性高，多线程增加了系统复杂度。

**Redis6.0 为什么要引入多线程呢？**

因为Redis的瓶颈不在内存，而是在网络I/O模块带来CPU的耗时，所以多线程是用来处理网络I/O这部分，充分利用CPU资源，Redis 的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程顺序执行，也就不存在并发安全问题

### 持久化

- Redis DataBase(简称RDB)
  - 执行机制：快照，直接将databases中的key-value的二进制形式存储在了rdb文件中
  - 优点：性能较高（因为是快照，且执行频率比aof低，而且rdb文件中直接存储的是key-values的二进制形式，对于恢复数据也快）
  - 使用单独子进程来进行持久化，主进程不会进行任何IO操作，保证了redis的高性能
  - 缺点：在save配置条件之间若发生宕机，此间的数据会丢失
  - RDB是间隔一段时间进行持久化，如果持久化之间redis发生故障，会发生数据丢失。所以这种方式更适合数据要求不严谨的时候
- Append-only file (简称AOF)
  - 执行机制：将对数据的每一条修改命令追加到aof文件
  - 优点：数据不容易丢失
  - 可以保持更高的数据完整性，如果设置追加file的时间是1s，如果redis发生故障，最多会丢失1s的数据；且如果日志写入不完整支持redis-check-aof来进行日志修复；AOF文件没被rewrite之前（文件过大时会对命令进行合并重写），可以删除其中的某些命令（比如误操作的flushall
  - 缺点：性能较低（每一条修改操作都要追加到aof文件，执行频率较RDB要高，而且aof文件中存储的是命令，对于恢复数据来讲需要逐行执行命令，所以恢复慢）
  - AOF文件比RDB文件大，且恢复速度慢。

### 分布式集群部署

redis的多机数据库实现，主要分为以下三种：

1. Redis哨兵（Sentinel）
2. Redis复制（主从）
3. Redis集群

#### Redis复制（主从）

当开启主从模式的时候，他的具体工作机制如下：

1. 当slave启动后会向master发送`SYNC`命令，master节后到从数据库的命令后通过`bgsave`保存快照（**「RDB持久化」**），并且期间的执行的些命令会被缓存起来。
2. 然后master会将保存的快照发送给slave，并且继续缓存期间的写命令。
3. slave收到主数据库发送过来的快照就会加载到自己的数据库中。
4. 最后master讲缓存的命令同步给slave，slave收到命令后执行一遍，这样master与slave数据就保持一致了。

优点：

- 解决了单机版并发量大，导致请求延迟或者redis宕机服务停止的问题。
- 实现读写分离
- 一定程度上提高了系统的可用性和性能，是实现哨兵和集群的基础

缺点：

- 数据的一致性问题
- 主从模式不具备自动容错和恢复的功能

#### 哨兵（Sentinel）模式

为了解决Redis的主从复制的不支持高可用性能，Redis实现了Sentinel哨兵机制解决方案。主从切换技术的方法是：当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造成一段时间内服务不可用。这不是一种推荐的方式，更多时候，我们优先考虑哨兵模式。

哨兵模式是一种特殊的模式，首先Redis提供了哨兵的命令，哨兵是一个独立的进程，作为进程，它会独立运行。其原理是哨兵通过发送命令，等待Redis服务器响应，从而监控运行的多个Redis实例。

这里的哨兵有两个作用

- 通过发送命令，让Redis服务器返回监控其运行状态，包括主服务器和从服务器。
- 当哨兵监测到master宕机，会自动将slave切换成master，然后通过**发布订阅模式**通知其他的从服务器，修改配置文件，让它们切换主机。

然而一个哨兵进程对Redis服务器进行监控，可能会出现问题，为此，我们可以使用多个哨兵进行监控。各个哨兵之间还会进行监控，这样就形成了多哨兵模式。

#### 集群（Cluster）

哨兵解决主从不能自动故障恢复的问题，但是同时也存在难以扩容以及单机存储、读写能力受限的问题，并且集群之前都是一台redis都是全量的数据，这样所有的redis都冗余一份，就会大大消耗内存空间。

集群是Redis提供的分布式数据库方案，集群通过分片来进行数据共享，并提供复制和故障转移功能。一个Redis集群通常由多个节点组成；最初，每个节点都是独立的，需要将独立的节点连接起来才能形成可工作的集群。

在Redis集群中采用的使虚拟槽分区算法，会把redis集群分成16384 个槽（0 -16383）。

Cluster Nodes命令和Cluster Meet命令，添加和连接节点形成集群。

## MongoDB

- 定义：mongoDB 是一种文档性的数据库。先解释一下文档的数据库，即可以存放xml、json、bson类型系那个的数据。

这些数据具备自述性（self-describing），呈现分层的树状数据结构。redis可以用hash存放简单关系型数据。

mongoDB 存放json格式数据。

- 适合场景：事件记录、内容管理或者博客平台，比如评论系统。

### 持久化原理

mongodb与mysql不同，mysql的每一次更新操作都会直接写入硬盘，但是mongo不会，做为内存型数据库，数据操作会先写入内存，然后再会持久化到硬盘中去，那么mongo是如何持久化的呢
mongodb在启动时，专门初始化一个线程不断循环（除非应用crash掉），用于在一定时间周期内来从defer队列中获取要持久化的数据并写入到磁盘的journal(日志)和mongofile(数据)处，当然因为它不是在用户添加记录时就写到磁盘上，所以按mongodb开发者说，它不会造成性能上的损耗，因为看过代码发现，当进行CUD操作时，记录(Record类型)都被放入到defer队列中以供延时批量（groupcommit）提交写入，但相信其中时间周期参数是个要认真考量的参数，系统为90毫秒，如果该值更低的话，可能会造成频繁磁盘操作，过高又会造成系统宕机时数据丢失过。

2：什么是NoSQL数据库？NoSQL和RDBMS有什么区别？在哪些情况下使用和不使用NoSQL数据库？
NoSQL是非关系型数据库，NoSQL = Not Only SQL。
关系型数据库采用的结构化的数据，NoSQL采用的是键值对的方式存储数据。
在处理非结构化/半结构化的大数据时；在水平方向上进行扩展时；随时应对动态增加的数据项时可以优先考虑使用NoSQL数据库。

在考虑数据库的成熟度；支持；分析和商业智能；管理及专业性等问题时，应优先考虑关系型数据库。

3.MySQL和MongoDB之间最基本的区别是什么？
关系型数据库与非关系型数据库的区别，即数据存储结构的不同。

4.MongoDB的特点是什么？
（1）面向文档（2）高性能（3）高可用（4）易扩展（5）丰富的查询语言

5.MongoDB支持存储过程吗？如果支持的话，怎么用？
MongoDB支持存储过程，它是javascript写的，保存在db.system.js表中。

6.如何理解MongoDB中的GridFS机制，MongoDB为何使用GridFS来存储文件？
GridFS是一种将大型文件存储在MongoDB中的文件规范。使用GridFS可以将大文件分隔成多个小文档存放，这样我们能够有效的保存大文档，而且解决了BSON对象有限制的问题。

7.为什么MongoDB的数据文件很大？
MongoDB采用的预分配空间的方式来防止文件碎片。

8.当更新一个正在被迁移的块（Chunk）上的文档时会发生什么？
更新操作会立即发生在旧的块（Chunk）上，然后更改才会在所有权转移前复制到新的分片上。

9.MongoDB在A:{B,C}上建立索引，查询A:{B,C}和A:{C,B}都会使用索引吗？
不会，只会在A:{B,C}上使用索引。

10.如果一个分片（Shard）停止或很慢的时候，发起一个查询会怎样？
如果一个分片停止了，除非查询设置了“Partial”选项，否则查询会返回一个错误。如果一个分片响应很慢，MongoDB会等待它的响应。

## 文档型数据库

- MongoDB与EleasticSearch相同点：

1、都是以json格式管理数据的nosql数据库。
2、都支持CRUD操作。
3、都支持聚合和全文检索。
4、都支持分片和复制。
5、都支持阉割版的join操作。
6、都支持处理超大规模数据。
7、目前都不支持事务或者叫支持阉割版的事务。

- 不同点：

1、开发语言不同：ES的Java语言(restful)，Mongo是C++语言(driver)，从开发角度来看，ES对Java更方便
2、分片方式：ES是hash，Mongo是range和hash
3、分布式：ES的主副分片自动组合和配置，Mongo需要手动配置集群“路由+服务配置+sharding”
4、索引：ES自建倒排索引，检索力度强，Mongo手动创建索引（B树），不支持倒排索引；es所有字段自动索引，mongodb的字段需要手动索引。
5、检索字段：ES全文检索，可用的检索插件较多，Mongo对索引字段个数有限制，全文检索效率低乃至不采用

- 倒排索引

倒排索引源于实际应用中需要**根据属性的值**来查找记录。这种索引表中的每一项都包括**一个属性值和具有该属性值的各记录的地址**。由于不是由记录来确定属性值，而是由属性值来确定记录的位置，因而称为倒排索引(inverted index) [参考](https://www.cnblogs.com/fly1988happy/archive/2012/04/01/2429000.html)

# 分布式

## CAP定理

一个分布式系统最多只能同时满足cap中的两项

- 一致性（Consistency）：所有节点在同一时间的数据完全一致
- 可用性（Availability）：服务在正常响应时间内一直可用
- 分区容错性（Partition tolerance）：分布式系统在遇到某节点或网络分区故障的时候，仍然能够对外提供满足一致性或可用性的服务

对于CAP理论中，分布式系统要保障整体的服务，因此分区容错性必然要保障

**CP：** 有些系统中一致性是本质要求，例如Redis分布式存储，ZooKeeper任何时候访问ZK都可以获得一致性的结果。极端情况下可能丢弃一些请求，从而保障一致性。 

**AP：** 比如有的网页对一致性要求不是那么高，对商品价格进行更改，但是要保障用户仍然能顺利的访问网页。但是会在付款的时候对价格进行再次验证。

## Base理论

指基本可用（Basically Available）、软状态（ Soft State）、最终一致性（ Eventual Consistency）。

BASE理论是对 CAP 中的一致性和可用性进行一个权衡的结果，通常的做法会选择AP舍弃C（舍弃强一致性但保证最终一致性）

## 一致性协议与算法

- **2PC（二阶段提交）**

  - 请求阶段
    在请求阶段，协调者将通知事务参与者准备提交或取消事务，然后进入表决过程。
    在表决过程中，参与者将告知协调者自己的决策：同意（事务参与者本地作业执行成功）或取消（本地作业执行故障）。
  - 提交阶段
    在该阶段，协调者将基于第一个阶段的投票结果进行决策：提交或取消。
    当且仅当所有的参与者同意提交事务协调者才通知所有的参与者提交事务。

- **3PC（三阶段提交）**

  三阶段提交针对两阶段提交做了改进：

  - 在第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与节点的状态是一致的。
  - 引入超时机制。在2PC中，只有协调者拥有超时机制，3PC同时在协调者和参与者中都引入超时机制。

- **TCC（补偿事务）**

  - Try：资源预留
  - Confirm：确认执行业务操作
  - Cancel：取消Try阶段预留的业务资源

  常用TCC开源框架：ByteTCC、Himly、TCC-transaction、seata

  参考文档：

  https://www.cnblogs.com/jajian/p/10014145.html

  http://www.tianshouzhi.com/api/tutorials/distributed_transaction/388



- Paxos：《优雅的Paxos算法》

- Raft ：《[Raft 一致性算法](https://www.zhihu.com/search?q=Raft+一致性算法&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A1795787642})》

- Gossip：《[Gossip Visualization](https://www.zhihu.com/search?q=Gossip+Visualization&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A1795787642})》

## 分布式锁

### 1. Redisson实现Redis分布式锁

Redis 有「互斥」的能力，我们可以使用 SETNX

- **死锁问题**：设置过期时间，SET $lock_key $unique_id EX $expire_time NX
- **过期时间不好评估，锁提前过期**：守护线程（watch dog），自动续期
- **释放了别人的锁**：锁写入唯一标识，释放锁先检查标识，再释放（判断和释放使用Lua保证原子操作）
- **可重入加锁机制**：重入时客户端1的加锁次数，累加1，释放时递减1，如果发现是0，删除锁

### 2. RedLock

Redlock 的方案基于 2 个前提：

1. 不再需要部署**从库**和**哨兵**实例，只部署**主库**
2. 但主库要部署多个，官方推荐至少 5 个实例

Redlock 的方案基于 2 个前提：

1. 客户端在多个 Redis 实例上申请加锁
2. 必须保证大多数节点加锁成功
3. 多数节点加锁的总耗时，要小于锁设置的过期时间
4. 释放锁，要向全部节点发起释放锁请求

### 3. Zookeeper

1. 客户端 1 和 2 都尝试创建「临时节点」，例如 /lock
2. 假设客户端 1 先到达，则加锁成功，客户端 2 加锁失败
3. 客户端 1 操作共享资源
4. 客户端 1 删除 /lock 节点，释放锁

Zookeeper 的优点：

1. zookeeper「临时节点」不需要考虑锁的过期时间
2. watch 机制，加锁失败，可以 watch 等待锁释放，实现乐观锁

缺点：

1. 性能不如 Redis
2. 部署和运维成本高
3. 客户端与 Zookeeper 的长时间失联，锁被释放问题

## SOA和微服务

SOA（Service Oriented Architecture）“面向服务的架构”:他是一种设计方法，其中包含多个服务， 服务之间通过相互依赖最终提供一系列的功能。一个服务 通常以独立的形式存在于操作系统进程中。各个服务之间 通过网络调用。

微服务架构:其实和 SOA 架构类似，微服务是在 SOA 上做的升华，微服务架构强调的一个重点是“业务需要彻底的组件化和服务化”，原有的单个业务系统会拆分为多个可以独立开发、设计、运行的小应用。这些小应用之间通过服务完成交互和集成。

