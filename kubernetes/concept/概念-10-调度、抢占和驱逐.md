- 调度 (scheduling) 指的是确保 Pod 匹配到合适的节点， 以便 kubelet 能够运行它们。 
- 抢占 (Preemption) 指的是终止低优先级的 Pod 以便高优先级的 Pod 可以调度运行的过程。
- 驱逐 (Eviction) 是在资源匮乏的节点上，主动让一个或多个 Pod 失效的过程

## Kubernetes 调度器

调度器通过 Kubernetes 的监测（Watch）机制来发现集群中新创建且尚未被调度到节点上的 Pod。 调度器会将所发现的每一个未调度的 Pod 调度到一个合适的节点上来运行。

kube-scheduler 是 Kubernetes 集群的默认调度器，并且是集群 控制面 的一部分。

## 将 Pod 指派给节点

你可以使用下列方法中的任何一种来选择 Kubernetes 对特定 Pod 的调度：

- 与节点标签匹配的 nodeSelector
- 亲和性与反亲和性
- nodeName 字段
- Pod 拓扑分布约束

### nodeSelector

该 Pod 将被调度到有 `disktype=ssd` 标签的节点。

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
  labels:
    env: test
spec:
  containers:
  - name: nginx
    image: nginx
    imagePullPolicy: IfNotPresent
  nodeSelector:
    disktype: ssd
```

`nodeName` 将某个 Pod 调度到特定的节点。

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  nodeName: foo-node # 调度 Pod 到特定的节点
  containers:
  - name: nginx
    image: nginx
    imagePullPolicy: IfNotPresent
```

### 亲和性与反亲和性

**亲和性**

什么是亲和性，简而言之，就是跟谁比较亲近，基于这个定义，我们就可以得到亲和性就是某个事物与某个事物比较亲近，那么既然亲近，我们就需要将这两个事物靠近，或者就让这些事物放在一起或者就近，以达到某种收益。在云计算的研究中，亲和性一般可以减少容器（虚拟机）之间的网络延迟或者减少通信能耗。

**反亲和性**

什么是反亲和性，通过上面的情况，其实我们反过来理解就可以明白了，那就是某个事物跟某个事物不仅亲近，而且还有仇。他们不能呆在一起，呆在一起就会出事，所以我们需要将其分开。

节点亲和性概念上类似于 `nodeSelector`， 它使你可以根据节点上的标签来约束 Pod 可以调度到哪些节点上。 节点亲和性有两种：

- `requiredDuringSchedulingIgnoredDuringExecution`： 调度器只有在规则被满足的时候才能执行调度。此功能类似于 `nodeSelector`， 但其语法表达能力更强。
- `preferredDuringSchedulingIgnoredDuringExecution`： 调度器会尝试寻找满足对应规则的节点。如果找不到匹配的节点，调度器仍然会调度该 Pod。

要使用 Pod 间亲和性

- `.affinity.podAffinity` ： 表示 Pod 间亲和性
- `.affinity.podAntiAffinity` ：表示对于 Pod 间反亲和性

> **说明：**
>
> 如果同时指定了 `nodeSelector` 和 `nodeAffinity`，**两者** 必须都要满足， 才能将 Pod 调度到候选节点上。
>
> 如果指定了多个与 `nodeAffinity` 类型关联的 `nodeSelectorTerms`， 只要其中一个 `nodeSelectorTerms` 满足，Pod 就可以被调度到节点上。
>
> 如果指定了多个与同一 `nodeSelectorTerms` 关联的 `matchExpressions`， 则只有当所有 `matchExpressions` 都满足时 Pod 才可以被调度到节点上。

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: web-server
spec:
  selector:
    matchLabels:
      app: web-store
  replicas: 3
  template:
    metadata:
      labels:
        app: web-store
    spec:
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - web-store
            topologyKey: "kubernetes.io/hostname"
        podAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: app
                operator: In
                values:
                - store
            topologyKey: "kubernetes.io/hostname"
      containers:
      - name: web-app
        image: nginx:1.16-alpine
```

 Deployment 会产生如下的集群布局，每个 Web 服务器与一个缓存实例并置， 并分别运行在三个独立的节点上。

|    node-1     |    node-2     |    node-3     |
| :-----------: | :-----------: | :-----------: |
| *webserver-1* | *webserver-2* | *webserver-3* |
|   *cache-1*   |   *cache-2*   |   *cache-3*   |

**topologyKey**

pod亲和性调度需要各个相关的pod对象运行于"同一位置"， 而反亲和性调度则要求他们不能运行于"同一位置"，

这里指定“同一位置” 是通过 topologyKey 来定义的，topologyKey 对应的值是 node 上的一个标签名称，比如各别节点zone=A标签，各别节点有zone=B标签，pod affinity topologyKey定义为zone，那么调度pod的时候就会围绕着A拓扑，B拓扑来调度，而相同拓扑下的node就为“同一位置”。

## 污点和容忍度

节点亲和性 是 Pod 的一种属性，它使 Pod 被吸引到一类特定的节点。污点则正好相反。

**污点（Taint）** ：它使节点能够排斥一类特定的 Pod。

**容忍度（Toleration）**：是应用于 Pod 上的。容忍度允许调度器调度带有对应污点的节点。 容忍度允许调度但并不保证调度：作为其功能的一部分， 调度器也会评估其他参数。

污点和容忍度（Toleration）相互配合，可以用来避免 Pod 被分配到不合适的节点上。 每个节点上都可以应用一个或多个污点，这表示对于那些不能容忍这些污点的 Pod， 是不会被该节点接受的。

给节点 `node1` 增加一个污点，它的键名是 `key1`，键值是 `value1`，效果是 `NoSchedule`。 这表示只有拥有和这个污点相匹配的容忍度的 Pod 才能够被分配到 `node1` 这个节点：

```sh
# 给节点增加污点：
kubectl taint nodes node1 key1=value1:NoSchedule
# 移除节点污点：
kubectl taint nodes node1 key1=value1:NoSchedule-
```

在yaml中展现：

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
  labels:
    env: test
spec:
  containers:
  - name: nginx
    image: nginx
    imagePullPolicy: IfNotPresent
  tolerations:
  - key: "example-key"
    operator: "Exists"
    effect: "NoSchedule"
```

`operator` 的默认值是 `Equal`。

一个容忍度和一个污点相“匹配”是指它们有一样的键名和效果，并且：

- 如果 `operator` 是 `Exists` （此时容忍度不能指定 `value`）
- 如果 `operator` 是 `Equal` ，则它们的 `value` 应该相等

> 如果一个容忍度的 `key` 为空且 `operator` 为 `Exists`， 表示这个容忍度与任意的 key、value 和 effect 都匹配，即这个容忍度能容忍任何污点。
>
> 如果 `effect` 为空，则可以与所有键名 `key1` 的效果相匹配。

处理逻辑：

- 如果未被忽略的污点中存在至少一个 effect 值为 `NoSchedule` 的污点， 则 Kubernetes 不会将 Pod 调度到该节点。
- 如果未被忽略的污点中不存在 effect 值为 `NoSchedule` 的污点， 但是存在 effect 值为 `PreferNoSchedule` 的污点， 则 Kubernetes 会 **尝试** 不将 Pod 调度到该节点。
- 如果未被忽略的污点中存在至少一个 effect 值为 `NoExecute` 的污点， 则 Kubernetes 不会将 Pod 调度到该节点（如果 Pod 还未在节点上运行）， 或者将 Pod 从该节点驱逐（如果 Pod 已经在节点上运行）。

## Pod 优先级和抢占

要使用优先级和抢占：

1. 新增一个或多个 PriorityClass。
2. 创建 Pod，并将其 `priorityClassName`设置为新增的 PriorityClass。 添加 `priorityClassName` 到集合对象（如 Deployment） 的 Pod 模板中。

**非抢占式 PriorityClass：**

配置了 `preemptionPolicy: Never` 的 Pod 将被放置在调度队列中较低优先级 Pod 之前， 但它们不能抢占其他 Pod。等待调度的非抢占式 Pod 将留在调度队列中，直到有足够的可用资源， 它才可以被调度。

**抢占式  PriorityClass：**

`preemptionPolicy 默认为 PreemptLowerPriority` 抢占逻辑试图找到一个节点， 在该节点中删除一个或多个优先级低于 P 的 Pod，则可以将 P 调度到该节点上。 如果找到这样的节点，一个或多个优先级较低的 Pod 会被从节点中驱逐。 被驱逐的 Pod 消失后，P 可以被调度到该节点上。

PriorityClass 示例：

```yaml
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: high-priority-nonpreempting
value: 1000000
preemptionPolicy: Never
globalDefault: false
description: "This priority class will not cause other pods to be preempted."
```

Pod 中设置优先级：

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx
  labels:
    env: test
spec:
  containers:
  - name: nginx
    image: nginx
    imagePullPolicy: IfNotPresent
  priorityClassName: high-priority
```